- You will find the main idea is to have more data on front-end over back-end.
- Between every adjacent requests there should be `\r\n` that separate between them.
- `content-length`: take consideration of `\r\n` and `chunkes sizer`. but you should leave `\n` not calculated to make HTTP smuggling.
- `chunker` “**`HEX value`**”: it count `\r\n` but there is `\r\n` after the chunk is ended that one doesn't get counted and **indecates the end of chunk** you can have multiple `\r\n` **but the one you don't calculate is the one that indecates the end of the chunk**, and after the `0` there should be `0\r\n` “next-line” `\r\n`.

- Back-end: if `content-length` is bigger than the actual data is transmitted then this will make timeout, the server will wait for the rest of data. But if the incoming data is more than the `content-length` the request is buffered and that creates the http request smuggling.
- Front-end:
	- If it use `TE` and we have put data under `Chunk size 0` "Request terminator", the rest of data will be dropped.
	- If it use `TE` and we didn't put `Chunk size 0` "Request terminator", the request will timeout.
	- if it use `CL` and we put `content-length` smaller than the actual data, the rest of data will be dropped.
	- if it use `CL` and we put `content-length` bigger than the actual data,  the front-end server will timeOut or reject. 

- You can test for HTTP smuggling for end-points that don't support POST request, that in normal cases works with GET request.

- most of times `transfer-encoding` have periority bigger than `content-length`, thats why you see many obfescation happen on `transfer-encoding`. The specification attempts to prevent this problem by stating that if both the `Content-Length` and `Transfer-Encoding` headers are present, then the `Content-Length` header should be ignored.

- Exploits that has `TE.X` which front-end use `TE`, you need to set the target exploit inside the chunk.

- If you managed to smuggle request perfectly without interfering with the victim request, this request will be directed to the server and no one will get the response, so you need at least to get one character from the victim request so you can have successful attack.
---
## Best practice
- The timing-based test for TE.CL vulnerabilities will potentially disrupt other application users if the application is vulnerable to the CL.TE variant of the vulnerability. So to be stealthy and minimize disruption, you should use the CL.TE test first and continue to the TE.CL test only if the first test is unsuccessful.

- The "attack" request and the "normal" request should be sent to the server using different network connections. Sending both requests through the same connection won't prove that the vulnerability exists.

- The "attack" request and the "normal" request should use the same URL and parameter names, as far as possible. This is because many modern applications route front-end requests to different back-end servers based on the URL and parameters. Using the same URL and parameters increases the chance that the requests will be processed by the same back-end server, which is essential for the attack to work.

- When testing the "normal" request to detect any interference from the "attack" request, you are in a race with any other requests that the application is receiving at the same time, including those from other users. You should send the "normal" request immediately after the "attack" request. If the application is busy, you might need to perform multiple attempts to confirm the vulnerability.

- In some applications, the front-end server functions as a load balancer, and forwards requests to different back-end systems according to some load balancing algorithm. If your "attack" and "normal" requests are forwarded to different back-end systems, then the attack will fail. This is an additional reason why you might need to try several times before a vulnerability can be confirmed.

- If your attack succeeds in interfering with a subsequent request, but this wasn't the "normal" request that you sent to detect the interference, then this means that another application user was affected by your attack. If you continue performing the test, this could have a disruptive effect on other users, and you should exercise caution.


> [!NOTE] 
> Websites that use HTTP/2 end-to-end are inherently immune to request smuggling attacks. As the HTTP/2 specification introduces a single, robust mechanism for specifying the length of a request, there is no way for an attacker to introduce the required ambiguity.
> 
> However, many websites have an HTTP/2-speaking front-end server, but deploy this in front of back-end infrastructure that only supports HTTP/1. This means that the front-end effectively has to translate the requests it receives into HTTP/1. This process is known as HTTP downgrading. For more information, see [Advanced request smuggling](https://portswigger.net/web-security/request-smuggling/advanced).
